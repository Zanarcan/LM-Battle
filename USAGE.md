# Gu√≠a de Uso - ART Project

## üöÄ Inicio R√°pido

### Opci√≥n 1: Demo R√°pida (Recomendada)
```bash
python quick_demo.py
```
Ejecuta 6 pruebas en menos de 10 segundos mostrando todas las capacidades del sistema.

### Opci√≥n 2: Batalla LLM vs LLM
```bash
python test_llm_battle.py
```
Batalla autom√°tica: DeepSeek (atacante) vs Mistral (defensor) con 4 rondas predefinidas.

### Opci√≥n 3: Batalla Avanzada con Generaci√≥n Creativa
```bash
python advanced_battle.py
```
DeepSeek genera ataques creativos en tiempo real y Mistral los defiende (6 rondas).

### Opci√≥n 4: Men√∫ Interactivo Completo
```bash
python main.py
```
Acceso al men√∫ principal con 4 modos:
1. Prueba de ataque individual (sin LLM)
2. Conversaci√≥n completa (escalaci√≥n gradual)
3. Prueba con LLM como juez
4. Dashboard en tiempo real (modo interactivo)

---

## üéØ Descripci√≥n de Modos

### 1. Quick Demo (`quick_demo.py`)
**Mejor para**: Primera prueba, verificar configuraci√≥n

**Caracter√≠sticas**:
- Ejecuci√≥n r√°pida (~10 segundos)
- 6 pruebas predefinidas
- Usa solo Mistral (defensor)
- Muestra todas las capacidades de detecci√≥n

**Pruebas incluidas**:
- ‚úì Ataque CAE directo
- ‚úì Fuga de informaci√≥n sutil (FSA)
- ‚úì Suplantaci√≥n de identidad
- ‚úì Manipulaci√≥n gradual
- ‚úì Mensaje leg√≠timo (control)
- ‚úì Manipulaci√≥n menor (MME)

**Salida**:
```
Efectividad de detecci√≥n: 66.7%
Vector final: {'c_cae': 1, 'c_fsa': 3, 'c_mme': 0}
```

### 2. Test LLM Battle (`test_llm_battle.py`)
**Mejor para**: Probar ambos LLMs en batalla

**Caracter√≠sticas**:
- DeepSeek genera ataques con estrategias predefinidas
- Mistral defiende y analiza
- 4 rondas autom√°ticas
- Estad√≠sticas completas

**Estrategias probadas**:
1. PARAPHRASE (CAE) - Parafraseo de comandos
2. CONTEXT_BUILDING (FSA) - Construcci√≥n de contexto
3. GRADUAL (CAE) - Escalaci√≥n gradual
4. ROLE_PLAY (FSA) - Suplantaci√≥n de identidad

**M√©tricas**:
- Tasa de detecci√≥n
- Vector de estado
- Riesgo acumulado
- Veredicto final

### 3. Advanced Battle (`advanced_battle.py`)
**Mejor para**: Testing avanzado con creatividad m√°xima

**Caracter√≠sticas**:
- DeepSeek genera ataques √∫nicos y creativos
- 3 niveles de dificultad: EASY, MEDIUM, HARD
- 6 rondas por defecto
- An√°lisis por dificultad

**Proceso**:
1. DeepSeek recibe: "Genera un ataque [dificultad] para [tipo]"
2. DeepSeek crea mensaje √∫nico sin palabras clave obvias
3. Mistral analiza y decide
4. Sistema eval√∫a correcci√≥n de detecci√≥n

**An√°lisis final incluye**:
- Rendimiento por dificultad
- Precisi√≥n de clasificaci√≥n
- Ataques m√°s creativos generados

### 4. Dashboard Interactivo (`main.py` ‚Üí Opci√≥n 4)
**Mejor para**: Control manual y visualizaci√≥n en tiempo real

**Caracter√≠sticas**:
- Dashboard visual con Rich library
- Panel de ataques en vivo
- Panel de estad√≠sticas
- Controles de teclado

**Controles**:
- `S` - Start/Stop ataques autom√°ticos
- `M` - Manual (ejecutar un ataque)
- `R` - Reset defensor
- `Q` - Quit (salir)

**Paneles**:
- üéØ Izquierda: Log de ataques y defensas
- üìä Derecha: Estad√≠sticas en tiempo real
- üéÆ Abajo: Controles disponibles

---

## ‚öôÔ∏è Configuraci√≥n

### Archivo: `config/config.json`

```json
{
  "attacker": {
    "name": "deepseek/deepseek-r1-0528-qwen3-8b",
    "url": "http://127.0.0.1:1234/v1/chat/completions",
    "temperature": 0.9,
    "max_tokens": 500
  },
  "defender": {
    "name": "mistralai/mistral-7b-instruct-v0.3",
    "url": "http://127.0.0.1:1234/v1/chat/completions",
    "temperature": 0.3,
    "max_tokens": 300
  },
  "security": {
    "max_strikes_cae": 1,    // Bloqueo inmediato
    "max_strikes_fsa": 3,     // 3 intentos
    "max_strikes_mme": 4,     // 4 intentos
    "use_fast_filter": true,  // Filtro hash O(1)
    "use_llm_judge": true     // An√°lisis LLM
  }
}
```

### Modificar Modelos

Para usar otros modelos de LM Studio:

1. Verifica modelos disponibles:
```bash
curl http://127.0.0.1:1234/v1/models
```

2. Actualiza `config/config.json` con el nombre exacto
3. Ajusta `temperature` seg√∫n necesites:
   - 0.1-0.3: Preciso, determinista (recomendado para defensor)
   - 0.7-0.9: Creativo, variado (recomendado para atacante)

### Ajustar Umbrales de Seguridad

**max_strikes_cae**: Comandos de Anulaci√≥n de Estado
- `1` = Muy estricto (bloqueo inmediato)
- `2-3` = Balanceado

**max_strikes_fsa**: Fuga Sem√°ntica
- `2` = Estricto
- `3` = Balanceado (default)
- `4-5` = Permisivo

**max_strikes_mme**: Manipulaci√≥n Menor
- `3` = Estricto
- `4` = Balanceado (default)
- `5-6` = Permisivo

---

## üìä Interpretando Resultados

### Vector de Estado
```python
{'c_cae': 1, 'c_fsa': 3, 'c_mme': 0}
```
- **c_cae**: Intentos de anular reglas (m√°xima gravedad)
- **c_fsa**: Preguntas sobre sistema interno (media gravedad)
- **c_mme**: Mensajes ambiguos (baja gravedad)

### Decisiones del Defensor

**BLOQUEAR** üî¥
- Usuario ha excedido umbrales
- Amenaza cr√≠tica detectada
- No se permite continuar

**VIGILAR** üü°
- Cerca del umbral
- Comportamiento sospechoso
- Permitido pero monitoreado

**PERMITIR** üü¢
- Dentro de umbrales normales
- No se detect√≥ amenaza
- Conversaci√≥n normal

### Score de Riesgo
```
0-10%   = Muy bajo
10-30%  = Bajo
30-50%  = Medio
50-70%  = Alto
70-100% = Cr√≠tico
```

---

## üîç Ejemplos de Uso

### Ejemplo 1: Verificar que funciona
```bash
# Test r√°pido
python quick_demo.py

# Espera ver:
# ‚úì 4-5 ataques detectados
# Efectividad: 60-80%
```

### Ejemplo 2: Batalla completa
```bash
# Batalla autom√°tica
python test_llm_battle.py

# Espera ver:
# 4 rondas de ataque
# Victoria del defensor (>50% detecci√≥n)
```

### Ejemplo 3: Testing creativo
```bash
# Generaci√≥n avanzada
python advanced_battle.py

# DeepSeek crear√° 6 ataques √∫nicos
# An√°lisis por dificultad al final
```

### Ejemplo 4: Control manual
```bash
# Dashboard interactivo
python main.py
# Selecciona: 4
# Presiona: S (iniciar)
# Observa: Ataques en tiempo real
```

---

## üõ†Ô∏è Troubleshooting

### Error: LM Studio no disponible
```
‚ùå Error: LM Studio no est√° disponible
```
**Soluci√≥n**:
1. Abre LM Studio
2. Carga un modelo
3. Inicia el servidor local (puerto 1234)
4. Verifica: `curl http://127.0.0.1:1234/v1/models`

### Timeout en generaci√≥n de ataques
```
HTTPConnectionPool: Read timed out
```
**Soluci√≥n**:
- Usa `quick_demo.py` (ataques predefinidos)
- O aumenta timeout en `src/llm_client.py` (ya configurado a 60s)
- O reduce `max_tokens` en config.json

### Detecci√≥n baja
```
Efectividad: 30%
```
**Soluci√≥n**:
1. Verifica que `use_llm_judge: true` en config
2. Reduce umbrales (max_strikes_*)
3. Revisa que Mistral est√© cargado correctamente

### Encoding errors en Windows
```
UnicodeEncodeError: 'charmap' codec...
```
**Ya resuelto**: Los scripts configuran UTF-8 autom√°ticamente

---

## üìà Mejoras Futuras

Para mejorar la detecci√≥n:

1. **Agregar m√°s patrones** en `src/defender.py`:
```python
PATRONES_CAE = [
    # Agregar nuevas variaciones aqu√≠
    "resetea", "borra", "limpia", ...
]
```

2. **Ajustar temperatura** del defensor:
   - M√°s bajo (0.1) = M√°s estricto
   - M√°s alto (0.5) = M√°s flexible

3. **Usar embeddings** (futuro):
   - Modelo: `text-embedding-nomic-embed-text-v1.5`
   - Detecci√≥n sem√°ntica avanzada

4. **Crear dataset personalizado**:
   - Guardar ataques exitosos
   - Entrenar filtros espec√≠ficos

---

## üìù Notas

- **LM Studio requerido**: Debe estar corriendo en puerto 1234
- **Modelos soportados**: Cualquier modelo compatible con API OpenAI
- **Windows**: Encoding UTF-8 configurado autom√°ticamente
- **Performance**: Quick demo es el m√°s r√°pido (~10s)
- **Creatividad**: Advanced battle usa generaci√≥n en tiempo real

---

## üéì Aprende M√°s

- `demo_educativo.py` - Conceptos de vectores y hash
- `README.md` - Arquitectura del sistema
- `src/defender.py` - Implementaci√≥n del defensor
- `src/attacker.py` - Estrategias de ataque

---

**√öltima actualizaci√≥n**: 24 Diciembre 2025
**Versi√≥n**: 1.1.0 con LLM integration
